{"cells":[{"cell_type":"code","execution_count":9,"id":"0bf9f039","metadata":{},"outputs":[{"data":{"text/plain":["spark = org.apache.spark.sql.SparkSession@3766e287\n","ratingsDF = [userId: string, movieId: string ... 2 more fields]\n","validRatingsDF = [userId: string, movieId: string ... 2 more fields]\n","ratingsRDD = MapPartitionsRDD[16] at map at <console>:65\n","ratingsGroupedByUserRDD = MapPartitionsRDD[18] at mapValues at <console>:72\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["import org.apache.spark.sql.{SparkSession, functions=>F}\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["MapPartitionsRDD[18] at mapValues at <console>:72"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["import org.apache.spark.sql.{SparkSession, functions => F}\n","import org.apache.spark.rdd.RDD\n","\n","val spark = SparkSession.builder()\n","      .appName(\"UserRatingHistoryPartitioning\")\n","      .master(\"local[*]\")\n","      .getOrCreate()\n","\n","val ratingsDF = spark.read.option(\"header\", \"true\").csv(\"gs://gcs_bucket_rupal/ratings.csv\")\n","\n","val validRatingsDF = ratingsDF.filter(\n","      F.col(\"userId\").isNotNull &&\n","      F.col(\"movieId\").isNotNull &&\n","      F.col(\"rating\").isNotNull\n","    ).withColumn(\"rating\", F.col(\"rating\").cast(\"double\"))\n","\n","val ratingsRDD = validRatingsDF.rdd.map(row => {\n","  val userId = row.getAs[String](\"userId\")\n","  val movieId = row.getAs[String](\"movieId\")\n","  val rating = row.getAs[Double](\"rating\")\n","  (userId, (movieId, rating))\n","})\n","\n","val ratingsGroupedByUserRDD = ratingsRDD.groupByKey().mapValues(_.toList)"]},{"cell_type":"code","execution_count":10,"id":"8a394367","metadata":{},"outputs":[{"data":{"text/plain":["outputPath = hdfs:///user/rupal_gupta/user-data/Q2\n","first10Users = Array((140868,List((5,3.0), (6,4.0), (7,4.0), (11,4.0), (17,3.0), (18,3.0), (21,4.0), (25,4.0), (32,3.0), (45,3.0), (50,5.0), (52,4.0), (57,4.0), (62,3.0), (64,3.0), (65,2.0), (70,3.0), (74,3.0), (75,3.0), (82,5.0), (85,4.0), (90,4.0), (93,3.0), (95,3.0), (96,5.0), (100,4.0), (102,3.0), (112,3.0), (125,4.0), (135,3.0), (141,4.0), (163,3.0), (171,5.0), (174,3.0), (176,5.0), (186,3.0), (187,3.0), (189,4.0), (194,4.0), (195,3.0), (203,3.0), (206,4.0), (215,3.0), (223,4.0), (224,4.0), (231,1.0), (232,5.0), (234,4.0), (235,5.0), (236,3.0), (237,3.0), (248,3.0), (252,4.0), (255,3.0)...\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["Array((140868,List((5,3.0), (6,4.0), (7,4.0), (11,4.0), (17,3.0), (18,3.0), (21,4.0), (25,4.0), (32,3.0), (45,3.0), (50,5.0), (52,4.0), (57,4.0), (62,3.0), (64,3.0), (65,2.0), (70,3.0), (74,3.0), (75,3.0), (82,5.0), (85,4.0), (90,4.0), (93,3.0), (95,3.0), (96,5.0), (100,4.0), (102,3.0), (112,3.0), (125,4.0), (135,3.0), (141,4.0), (163,3.0), (171,5.0), (174,3.0), (176,5.0), (186,3.0), (187,3.0), (189,4.0), (194,4.0), (195,3.0), (203,3.0), (206,4.0), (215,3.0), (223,4.0), (224,4.0), (231,1.0), (232,5.0), (234,4.0), (235,5.0), (236,3.0), (237,3.0), (248,3.0), (252,4.0), (255,3.0)..."]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["import org.apache.hadoop.fs.{FileSystem, Path}\n","import java.io.{BufferedWriter, OutputStreamWriter}\n","\n","val outputPath = \"hdfs:///user/rupal_gupta/user-data/Q2\"\n","    val first10Users = ratingsGroupedByUserRDD.take(10)\n","first10Users.foreach { case (userId, ratingsList) =>\n","  val userFolderPath = s\"${outputPath}/${userId}/ratings.csv\"\n","  val path = new Path(userFolderPath)\n","  \n","  val fs = FileSystem.get(new java.net.URI(\"hdfs:///\"), new org.apache.hadoop.conf.Configuration())\n","  \n","  if (!fs.exists(path.getParent)) {\n","    fs.mkdirs(path.getParent)\n","  }\n","\n","  val ratingsText = ratingsList.map { case (movieId, rating) =>\n","    s\"${movieId}, ${rating}\"\n","  }.mkString(\"\\n\")\n","\n","  val outputStream = fs.create(path)\n","  val writer = new BufferedWriter(new OutputStreamWriter(outputStream))\n","\n","  writer.write(ratingsText)\n","\n","  writer.close()\n","  outputStream.close()\n","}\n","  spark.stop()"]},{"cell_type":"code","execution_count":null,"id":"4608f787","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Apache Toree - Scala","language":"scala","name":"apache_toree_scala"},"language_info":{"codemirror_mode":"text/x-scala","file_extension":".scala","mimetype":"text/x-scala","name":"scala","pygments_lexer":"scala","version":"2.12.15"}},"nbformat":4,"nbformat_minor":5}